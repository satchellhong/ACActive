{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8abd070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298 313 313 268 301] 298.6\n",
      "[349 335 329 273 293] 315.8\n",
      "16.475436261295176\n",
      "28.27295527531567\n",
      "p-value: [       nan 0.5291333  0.51764812 0.45945266 0.48585384 0.51710249\n",
      " 0.46832059 0.29498379 0.22717688 0.47064922 0.58512811 0.64316872\n",
      " 0.95142157 0.45299349 0.33979483 0.15655335]\n",
      "p-value: 0.1565533523\n",
      "[34 28 25  8 35] 26.0\n",
      "[33 35 27 32 46] 34.6\n",
      "9.736529155710468\n",
      "6.280127387243033\n",
      "p-value: [       nan 0.37390097 0.09930068 0.43096867 0.66508573 0.36907705\n",
      " 0.7201997  0.69889314 0.57100219 0.78238137 0.94062221 0.40558273\n",
      " 0.18407403 0.13103213 0.12495216 0.12018776]\n",
      "p-value: 0.1201877638\n",
      "[29 43 42 32 60] 41.2\n",
      "[45 47 51 34 67] 48.8\n",
      "10.870142593360953\n",
      "10.703270528207721\n",
      "p-value: [       nan 0.47662067 0.31685485 0.5354236  0.68845709 0.68270603\n",
      " 0.36016899 0.7007472  0.66085822 1.         0.47662067 0.12835349\n",
      " 0.01751619 0.04509118 0.10454    0.03486348]\n",
      "p-value: 0.0348634794\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "'''\n",
    "ALDH1 : 319\n",
    "PKM2 : 36\n",
    "VDR : 52\n",
    "'''\n",
    "for dataset in ['ALDH1', 'PKM2', 'VDR']:\n",
    "    dir1 = {'ALDH1': f'75. fp+mf+um_attention_2', \n",
    "            'PKM2': f'75. fp+mf+um_attention_2', \n",
    "            'VDR': f'75. fp+mf+um_attention_2'}\n",
    "    file1 = {'ALDH1': f'75. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_256', \n",
    "            'PKM2': f'75. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_64', \n",
    "            'VDR': f'75. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_128_layer2'}\n",
    "    # dir2 = {'ALDH1': f'81. fp+mf+um_attention_seq_kl_T1_ratio0.25', \n",
    "    #         'PKM2': f'81. fp+mf+um_attention_seq_kl_T1_ratio0.25', \n",
    "    #         'VDR': f'81. fp+mf+um_attention_seq_kl_T1_ratio0.5'}\n",
    "    # file2 = {'ALDH1': f'81. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_256_layer2_cycle1_lambdaVar', \n",
    "    #         'PKM2': f'81. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_1024_512_cycle1_lambdaVar', \n",
    "    #         'VDR': f'81. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_64_cycle2_lambdaVar'}\n",
    "    dir2 = {'ALDH1': f'82. fp+mf+um_attention_ucb_1', \n",
    "            'PKM2': f'82. fp+mf+um_attention_ucb_1', \n",
    "            'VDR': f'82. fp+mf+um_attention_ucb_1'}\n",
    "    file2 = {'ALDH1': f'82. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_256_beta1', \n",
    "            'PKM2': f'82. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_256_layer2_beta0.5', \n",
    "            'VDR': f'82. {dataset}_exploitation_mlp_fp+mf+um_0_nonorm_512_128_layer2_beta0.75'}\n",
    "    acqf = 'exploitation'\n",
    "    arch1 = 'mlp'\n",
    "    num_hit1 = []\n",
    "    num_hit2 = []\n",
    "\n",
    "    data1 = pd.read_csv(f'../results_0924/{dir1[dataset]}/{file1[dataset]}/{file1[dataset]}.csv')\n",
    "    data2 = pd.read_csv(f'../results_1014/{dir2[dataset]}/{file2[dataset]}/{file2[dataset]}.csv')\n",
    "\n",
    "    for i in range(16):\n",
    "        data = data1[(data1['acquisition_method'] == acqf) & (data1['architecture'] == arch1) & (data1['dataset'] == dataset) \\\n",
    "                & (data1['screen_cycle'] == i)]\n",
    "        num_hit1.append(list(data['hits_discovered']))\n",
    "\n",
    "    for i in range(16):\n",
    "        data = data2[(data2['acquisition_method'] == acqf) & (data2['architecture'] == arch1) & (data2['dataset'] == dataset) \\\n",
    "                & (data2['screen_cycle'] == i)]\n",
    "        num_hit2.append(list(data['hits_discovered']))\n",
    "\n",
    "    num_hit1 = np.array(num_hit1).T\n",
    "    num_hit2 = np.array(num_hit2).T\n",
    "    print(num_hit1[:,-1], num_hit1[:,-1].mean())\n",
    "    # num_hit1[3,-1] = 30\n",
    "    print(num_hit2[:,-1], num_hit2[:,-1].mean())\n",
    "\n",
    "    print(num_hit1[:,-1].std())\n",
    "    print(num_hit2[:,-1].std())\n",
    "\n",
    "    t_stat, p_value = stats.ttest_rel(num_hit1, num_hit2)\n",
    "    # print(\"t-statistic:\", t_stat)\n",
    "    print(\"p-value:\", p_value)\n",
    "\n",
    "    t_stat, p_value = stats.ttest_rel(num_hit1[:,-1], num_hit2[:,-1])\n",
    "    # print(\"t-statistic:\", round(t_stat,4))\n",
    "    print(\"p-value:\", round(p_value,10))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26db704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import BRICS\n",
    "from collections import defaultdict\n",
    "\n",
    "def brics_decomp(smiles_list, label_list):\n",
    "    result = defaultdict(list)\n",
    "    set_result = defaultdict(list)\n",
    "\n",
    "    for smi, label in zip(smiles_list, label_list):\n",
    "        brics_list = []\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fragments = BRICS.BRICSDecompose(mol)\n",
    "        for frag in fragments:\n",
    "            brics_list.append(frag)\n",
    "        result[label].append(brics_list)\n",
    "        set_result[label].extend(brics_list)\n",
    "\n",
    "    # 중복 제거\n",
    "    total_frag_set = list(set(set_result[0]) | set(set_result[1]))\n",
    "\n",
    "    # fragment별 positive / negative 개수 세기\n",
    "    frag_stats = []\n",
    "    for frag in total_frag_set:\n",
    "        pos_count = sum(frag in frags for frags in result[1])\n",
    "        neg_count = sum(frag in frags for frags in result[0])\n",
    "        total = pos_count + neg_count\n",
    "        ratio = pos_count / total if total > 0 else 0\n",
    "        frag_stats.append({\n",
    "            'fragment': frag,\n",
    "            'positive_count': pos_count,\n",
    "            'negative_count': neg_count,\n",
    "            'positive_ratio': ratio\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(frag_stats)\n",
    "    return df.round(5)\n",
    "\n",
    "brics_dict = {}\n",
    "for dataset in ['ALDH1', 'VDR']:\n",
    "    data1 = pd.read_csv(f'../data/{dataset}/original/screen.csv')\n",
    "    positive = data1[data1['y'] == 1]\n",
    "    smiles_list = data1['smiles']\n",
    "    label_list = data1['y']\n",
    "\n",
    "    df = brics_decomp(smiles_list, label_list)\n",
    "    df.to_csv(f'./result_brics_{dataset}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for dataset in ['ALDH1', 'PKM2', 'VDR']:\n",
    "        data = pd.read_csv(f'./result_brics_{dataset}.csv')\n",
    "    data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACANET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
